---
title: "Analiza danych - laboratorium 7"
subtitle: 'Test t-studenta - wprowadzenie' 
author: 
  name: 'Adrian Kowalski'
  affiliation: 'Politechnika Krakowska'
output: html_notebook
---
```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```
# Problem pierwszy

W kawiarni ktoś zapytał bariste, czy jeżeli pił już napój energetyczny o zawartości kofeiny $32$mg na $100$ml to czy nie przekroczy zalecanej dawki kofeiny po wypiciu jednego espresso. Barista bazując na swoim doświadczeniu powiedział mu, że takie espresso ma średnio $120$mg kofeiny, więc wszystko powinno być w porządku, ze względu na to, że zalecana dzienna dawka kofeiny do sporzycia dla dorosłego to taka nie przekraczająca $400$mg. Później jednak barista zaczął się zastanawiać, czy się nie pomylił. Zaparzył więc 36 espresso i zmierzył ich zawartość kofeiny. Czy dostarczył wystarczającą ilość dowodów na to, że się pomylił?
```{r, message=FALSE}
caffeine <- read_csv("lab7dt1.csv")
head(caffeine)
```

# Próba rozwiązania problemu

Załóżmy na sam początek, że znamy odchylenie standardowe ilości kofeiny w espresso, niech na nasze potrzeby $\sigma = 5$. Wówczas to co musimy zbadać, czy na podstawie próby zebranej przez bariste możemy coś powiedzieć o wszystkich możliwych espresso. Załózmy, że prawdziwa średnia ilość kofeiny w espresso wynosi $\mu = 120$. To założenie będziemy nazywać *hipotezą zerową* i oznaczamy $H_0 : \mu = 120$. Wobec tego, alternatywą, czy też, *hipotezą alternatywną* jest stwierdzenie $H_1 : \mu \neq 120$. Przy założeniu prawdziwości hipotezy zerowej możemy skonstruować tzw. statystykę testową. Oznaczmy przez $X_i$ ilość kofeiny w $i$-tym espresso. Załóżmy, że $X_i$ mają jednakowy rozkład normalny $N(120,5)$. Wówczas zmienna
\[ Z = \frac{\frac{1}{36}\sum_{i=1}^{36}X_i - 120}{\frac{5}{\sqrt{36}}} \sim N(0,1). \]

W świetle reguły $3 \sigma$ wiemy, że $95\%$ obserwacji z rozkładu $N(0,1)$ znajduje się w przedziale $[-2,2]$. Chcemy zatem sprawdzić, czy otrzymana przez nas obserwacja $z$(wyliczona z próby) jest typowa czy nie. Innymi słowy, ile wynosi $P(|Z| > |z|)$. Zauważmy, że rozkład normalny jest symetryczny względem zera, zatem $P(|Z|>|z|) = P(Z > |z|) + P(Z < - |z|) = 2P(|Z| >|z|)$. Możemy zatem porównać naszą wartość $|z|$ z kwantylami $0.025$ i $0.975$ rozkładu $N(0,1)$, aby otrzymać informację o tym, czy nasza obserwacja jest typowa czy nie. Jeżeli nasza obserwacja $-|z| < Z_{0.025}$ lub $|z| > Z_{0.975}$ to mamy wystaczające dowody na to, że obserwacja jest nietypowa, więc założenie o średniej $120$ było błędne.

Liczbę $0.05$ od teraz będziemy oznaczać $\alpha$ i nazywać *rozmiarem* testu. Sprawdźmy jak to wygląda w naszym przykładzie. Zbiory $-|z| < Z_{0.025}$ i $|z| > Z_{0.975}$ nazywamy *obszarami decyzyjnymi*.


```{r, echo=FALSE}
nden <- tibble(values = seq(-3,3,0.1)) %>% mutate(density = dnorm(values))
n <- length(caffeine$caffeine)
Z_sd <- 5
mu0 <- 120
Z_stat <- ((1/n)*sum(caffeine$caffeine) - mu0)/(Z_sd/sqrt(n))
ggplot(data = nden, aes(x=values, y=density)) + geom_area(alpha = 0.3, color='blue') + geom_vline(xintercept=qnorm(0.025), linetype='dashed', color='red') + geom_vline(xintercept=qnorm(0.975), linetype='dashed', color='red') + geom_vline(xintercept=Z_stat, color='green') + ggtitle("Obszary decyzyjne dla testu Z")
```

```{r}
paste("Kwantyl 0.025:", round(qnorm(0.025),2), "Kwantyl 0.975:", round(qnorm(0.975),2), "Nasza wartość z próby:", round(Z_stat,2))
```

# Porzucenie założenia o wariancji

Nasze powyższe rozumowania bardzo mocno opierały się na założeniu, że znamy wariancje, więc nie popełniamy błędu szacując ją z próby. W rzeczywistości taka sytuacja jest wielce niespotykana i jednak musimy użyć oszacowania wariancji z próby. Wówczas zmienna 

\[ T = \frac{\frac{1}{n}\sum_{i=1}^n X_i - \mu}{\frac{s}{\sqrt{n}}} \sim t(n-1) \]

ma rozkład $t$ studenta o $n-1$ stopniach swobody. (Przypomijmy, że dla dużych ilośći stopni swobody taki rozkład możemy przybliżać za pomocą rozkładu normalnego). Rozkład $t$ również jest symetryczny względem zera, więc procedura doboru kwartyli pozostanie taka sama, jedynie teraz wybieramy je z rozkładu $t$-studenta.


```{r,echo=FALSE}
n <- length(caffeine$caffeine)
nden <- tibble(values = seq(-3,3,0.1)) %>% mutate(density = dt(values, n-1))
Z_sd <- sqrt((1/(n-1))*sum((caffeine$caffeine-mean(caffeine$caffeine))^2))
mu0 <- 120
Z_stat <- (mean(caffeine$caffeine) - mu0)/(Z_sd/sqrt(n))
ggplot(data = nden, aes(x=values, y=density)) + geom_area(alpha = 0.3, color='blue') + geom_vline(xintercept=qt(0.025, n-1), linetype='dashed', color='red') + geom_vline(xintercept=qt(0.975, n-1), linetype='dashed', color='red') + geom_vline(xintercept=Z_stat, color='green') + ggtitle("Obszary decyzyjne dla testu t studenta")
```

Test $t$ studenta możemy również przeprowadzić za pomocą polecenia **t.test()**.
```{r}
Z_stat
t.test(caffeine$caffeine, mu=120)
```

Output funkcji *t.test* zwraca nam dodatkowe dwie informacje. Po pierwsze tzw. *przedział ufności*, którym zajmiemy się już niebawem. Do tego zwraca nam $p$-value. Jest to dokładnie wartość $P(|Z|>|z| | H_0)$. Możemy nie odwoływać się zatem do obszarów decyzyjnych, a polegać jedynie na $p$-value przy wnioskowaniu z testu. Jeżeli $p$-value jest mniejsze niż $0.05$ (lub dowolny inny ustalony przez nas rozmiar testu), to mamy wystarczające dowody, by odrzucić $H_0$.

# Co jeżeli wątpimy w normalność populacji?

Istnieją alternatywy, jeżeli poddajemy wątpliwośći normalność populacji, z której pochodzi nasza próba. Jedną z takich alternatyw jest metoda symulacyjna **bootstrap**. Procedura przebiega następująco.

### Zakładamy hipoteze zerową

Przy założeniu $H_0: \mu = 120$, centrujemy nasze obserwacje tak, aby średnia w nowej, sztucznej próbie wynosiła $120$.

```{r}
bootstrap_caffeine <- caffeine$caffeine - mean(caffeine$caffeine) + 120
```

### Konstruujemy statystykę "bootstrap'ową"

Próbkujemy, z powtórzeniami, $n$ elementową próbę z naszej próby sztucznej odpowiednią ilość razy (chociażby $5000$). Dla każdej takiej sztucznej próby wyznaczamy statystykę testową 
\[ t = \frac{\bar{Z}-\mu}{\frac{s}{\sqrt{n}}}. \]

```{r}
bootstrap_stat <- rep(0,5000)
mu0 <- 120
compute_z <- function(sample,mu){
  se <- sqrt((1/(n-1))*sum((sample-mean(sample))^2))
  return((mean(sample)-mu)/((se)/sqrt(n)))
}
for(i in 1:5000){
  curr_sample <- sample(bootstrap_caffeine, size=n, replace=TRUE)
  bootstrap_stat[i] <- compute_z(curr_sample, mu0)
}
head(bootstrap_stat)
```

```{r}
bootstrap_stat_tbl <- tibble(stat = bootstrap_stat)
ggplot(data = bootstrap_stat_tbl, aes(x = stat)) + geom_histogram(binwidth=0.5)
```

### Obliczamy p-value

```{r}
bootstrap_p <- sum((bootstrap_stat <= -abs(Z_stat))|(bootstrap_stat >= abs(Z_stat)))/5000

paste("p-value testu bootstrap wynosi", round(bootstrap_p, 4))
```

# Przedziały ufności za pomocą bootstrap

Za pomocą metody bootstrap można również wyznaczać w sposób nieparametryczny przedziały ufności. Zacznijmy więc od nich. Ale co to w zasadzie jest przedział ufności? Formalnie, przedziałem ufności parametru $\theta$ na poziomie $\alpha$ jest przedział dany zmiennymi losowymi $(X_l,X_u)$ spełniający własność
\[ P(X_l < \theta < X_u) = 1-\alpha. \]

Wyznaczaniem przedziałów ufności zajmiemy się w następnym notatniku.

